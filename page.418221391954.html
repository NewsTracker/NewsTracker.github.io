<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css">
<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap-theme.min.css">
<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<style>img { width: 150px; height: auto; }</style>
</head>
<body role="document">
<div class="container theme-showcase" role="main">
<h3>Google 'genuinely sorry' after report photo app tagged black people 'gorillas'</h3>
<table class="table table-striped"><tr><td>1</td><td>The "Google" logo is pictured.</td></tr>
<tr><td>2</td><td>SAN FRANCISCO -- Google's new image-recognition program misfired badly this week by identifying two black people as gorillas, delivering a mortifying reminder that even the most intelligent machines still have lot to learn about human sensitivity.</td></tr>
<tr><td>3</td><td>The blunder surfaced in a smartphone screen shot posted online Sunday by a New York man on his Twitter account, aojackyalcine.</td></tr>
<tr><td>4</td><td>The images showed the recently released Google Photos app had sorted a picture of two black people into a category labeled as "gorillas."</td></tr>
<tr><td>5</td><td>The accountholder used a profanity while expressing his dismay about the app likening his friend to an ape, a comparison widely regarded as a racial slur when applied to a black person.</td></tr>
<tr><td>6</td><td>"We're appalled and genuinely sorry that this happened," Google spokeswoman Katie Watson said.</td></tr>
<tr><td>7</td><td>"We are taking immediate action to prevent this type of result from appearing."</td></tr>
<tr><td>8</td><td>A tweet to aojackyalcine requesting an interview hadn't received a response several hours after it was sent Thursday.</td></tr>
<tr><td>9</td><td>Despite Google's apology, the gaffe threatens to cast the Internet company in an unflattering light at a time when it and its Silicon Valley peers have already been fending off accusations of discriminatory hiring practices.</td></tr>
<tr><td>10</td><td>Those perceptions have been fed by the composition of most technology companies' workforces, which mostly consist of whites and Asians with a paltry few blacks and Hispanics sprinkled in.</td></tr>
<tr><td>11</td><td>The mix-up also surfaced amid rising U.S. racial tensions that have been fueled by recent police killings of blacks and last month's murder of nine black churchgoers in Charleston, South Carolina.</td></tr>
<tr><td>12</td><td>Google's error underscores the pitfalls of relying on machines to handle tedious tasks that people have typically handled in the past.</td></tr>
<tr><td>13</td><td>In this case, the Google Photo app released in late May uses recognition software to analyze images in pictures to sort them into a variety of categories, including places, names, activities and animals.</td></tr>
<tr><td>14</td><td>When the app came out, Google executives warned it probably wouldn't get everything right -- a point that has now been hammered home.</td></tr>
<tr><td>15</td><td>Besides mistaking humans for gorillas, the app also has been mocked for labeling some people as seals and some dogs as horses.</td></tr>
<tr><td>16</td><td>"There is still clearly a lot of work to do with automatic image labeling," Watson conceded.</td></tr>
<tr><td>17</td><td>Some commentators in social media, though, wondered if the flaws in Google's automatic-recognition software may have stemmed on its reliance on white and Asian engineers who might not be sensitive to labels that would offend black people.</td></tr>
<tr><td>18</td><td>About 94 per cent of Google's technology workers are white or Asian and just 1 per cent is black, according to the company's latest diversity disclosures.</td></tr>
<tr><td>19</td><td>Google isn't the only company still trying to work out the bugs in its image-recognition technology.</td></tr>
<tr><td>20</td><td>Shortly after Yahoo's Flickr introduced an automated service for tagging photos in May, it fielded complaints about identifying black people as "apes" and "animals."</td></tr>
<tr><td>21</td><td>Flickr also mistakenly identified a Nazi concentration camp as a "jungle gym."</td></tr>
<tr><td>22</td><td>Google reacted swiftly to the mess created by its machines, long before the media began writing about it.</td></tr>
<tr><td>23</td><td>Less than two hours after aojackyalcine posted his outrage over the gorilla label, one of Google's top engineers had posted a response seeking access to his account to determine what went wrong.</td></tr>
<tr><td>24</td><td>Yonatan Zunger, chief architect of Google's social products, later tweeted: "Sheesh. High on my list of bugs you never want to see happen. Shudder."</td></tr>
</table></body></div></html>